# -*- coding: utf-8 -*-
"""test-technique-AMAGUINE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15PQ-0ahYgBiWYSc2k0L92aof3-hBon4N
"""

# Importation des bibliothèques nécessaires
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
import xgboost as xgb
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from imblearn.over_sampling import SMOTE
from sklearn.metrics import roc_auc_score

"""#1. Exploration des données"""

# 1. Chargement des données
data = pd.read_excel('/content/test_technique_dataset.xlsx')
data.shape

# 2. Aperçu des données
# Affichage des premières lignes du dataset pour avoir une idée générale de ce qu'il contient
print(data.head())

# 3. Informations générales sur les colonnes
# Cela nous donne une idée des types de données, du nombre de valeurs non nulles, etc.
print(data.info())

# 4. Statistiques descriptives
# Cela nous donne des informations comme la moyenne, l'écart-type, le min/max, etc. pour chaque colonne numérique
print(data.describe())

# 5. Vérification des valeurs manquantes
# Ceci nous aidera à décider comment traiter ces valeurs plus tard
print(data.isnull().sum())

# 6. Exploration des variables catégorielles
print(data['job_category'].value_counts())

# 7. Visualisations

# Distribution de la variable 'annual_flux'
# Utiliser une échelle logarithmique pour mieux visualiser
data['log_annual_flux'] = data['annual_flux'].apply(lambda x: 0 if x == 0 else np.log(x))
sns.histplot(data['log_annual_flux'], kde=True)
plt.title('Logarithmic Distribution of Annual Flux')
plt.show()

# Supprimons la colonne log_annual_flux pour garder le jeu de données original propre.
data.drop('log_annual_flux', axis=1, inplace=True)

# Matrice de corrélation
corr_matrix = data.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

"""# 2. Analyse des données

"""

# 1. Traitement des valeurs manquantes
# Remplacer les valeurs manquantes des colonnes numériques par la médiane
numerical_cols = data.select_dtypes(include=[np.number]).columns.tolist()
for col in numerical_cols:
    data[col].fillna(data[col].median(), inplace=True)

# Vérification
print(data.isnull().sum())

# Remplacer les valeurs manquantes des colonnes catégorielles par la mode
categorical_cols = data.select_dtypes(include=[object]).columns.tolist()
for col in categorical_cols:
    data[col].fillna(data[col].mode()[0], inplace=True)

# Vérification
print(data.isnull().sum())
data.dtypes

data['target'].value_counts()

# 3. Encodage des variables catégorielles
# Encodage One-Hot pour transformer les colonnes catégorielles en format numérique
data = pd.get_dummies(data, drop_first=True)

# Vérification
print(data.isnull().sum())
data.dtypes

# 5.  Division du dataset

X = data.drop('target', axis=1)
y = data['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
X.to_csv('train.csv', index=False)
y.to_csv('test.csv', index=False)

# 6.  Utilisation de SMOTE pour équilibrer les classes
print("Distribution des classes avant SMOTE :")
print(y_train.value_counts())

smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

print("Distribution des classes après SMOTE :")
print(y_train_smote.value_counts())

"""# 3. Modélisation et performance


"""

# Choix du modèle : XGBoost avec des hyperparamètres de base

#clf = RandomForestClassifier(random_state=42)
#clf.fit(X_train_smote, y_train_smote)

#clf = XGBClassifier(random_state=42)
#clf.fit(X_train_smote, y_train_smote)


ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)  # ratio of negative to positive samples

clf_xgb = xgb.XGBClassifier(
    scale_pos_weight=ratio,
    objective='binary:logistic',
    eval_metric='auc',
    use_label_encoder=False
)

clf_xgb.fit(X_train_smote, y_train_smote)

y_pred_xgb = clf_xgb.predict(X_test)
cm=confusion_matrix(y_test, y_pred_xgb)
print(confusion_matrix(y_test, y_pred_xgb))
print(classification_report(y_test, y_pred_xgb))
print("AUC-ROC:", roc_auc_score(y_test, y_pred_xgb))

# Sauvegarde des prédictions
predictions_df = pd.DataFrame(y_pred_xbg, columns=['prediction'])
predictions_df.to_csv('predictions.csv', index=False)

# Sauvegarde de la matrice de confusion
confusion_df = pd.DataFrame(cm)
confusion_df.to_csv('confusion_matrix.csv', index=False)